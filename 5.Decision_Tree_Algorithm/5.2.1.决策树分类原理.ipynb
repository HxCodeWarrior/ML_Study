{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "决策树分类原理",
   "id": "8fe393c5e352c852"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "1.熵",
   "id": "672e5cf48def05ba"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "    1.1.概念\n",
    "        物理学上，熵Entropy是“混乱”程度的意思\n",
    "        \n",
    "        系统越有序，熵值越低；系统越混乱或者分散，熵值越高。\n",
    "![juppyter](../Sources/Pictures/Decision_Tree_Algorithm/熵概念图解.png)"
   ],
   "id": "a1f7c2e080c7f60c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "    信息论：\n",
    "        （1）从信息的完整性上进行的描述：\n",
    "            当系统的有序状态一致时，数据越集中而得地方熵值越小，数据越分散的地方熵值越大。\n",
    "        （2）从信息的有序性上进行描述：\n",
    "            当数据量一致时，系统越有序，熵值越低；\n",
    "            系统越混乱或者分散，熵值越高。"
   ],
   "id": "41fd9dfb10fcc680"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "    “信息熵”（information entropy）是度量样本级和纯度最常用的一种指标。\n",
    "    假定当前样本集合D中第k类样本所占的比例为pk(k=1,2,3,……，|y|)\n",
    "    pk = （C^k）/ D\n",
    "    解释：D为样本的所有数量，C^k为第k类样本的数量"
   ],
   "id": "804980bbd8878d42"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "    则D的信息熵定义为(log是以2为底，lg是以10为底)\n",
    "    其中：Ent(D)的值越小，则D的纯度越高\n",
    "![jupyter](../Sources/Pictures/Decision_Tree_Algorithm/信息熵公式.png)"
   ],
   "id": "2684b152bfef39e3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "    1.2.案例\n",
    "    假设：\n",
    "        假设我们没有看过世界杯，但是想知道哪支球队会是冠军，我们只能猜测某支球队是或\n",
    "        者不是冠军，然后观众用对或者不对来回答，我们想要猜测次数尽可能少。\n",
    "    答案：\n",
    "        【二分法】\n",
    "        假如有16支球队，分别编号，先问是否在1-8之间，\n",
    "        如果十九继续问是否在1-4之间，以此类推，指导最后判断出冠军球队是哪支队伍。\n",
    "        如果球队数量是16，我们需要问4次来得到最后的答案。那么实际冠军这条消息的信息熵就是4.\n",
    "    那么信息熵等于4，是如何进行计算的呢？\n",
    "        Ent(D) = -(p1*logp1 + p2*logp2……+ p16*logp16)\n",
    "        其中p1，……，p16分别是这16支球队夺冠的概率\n",
    "        当每支球队夺冠概率相等的概率都是1/16时：Ent(D)=-(16*(1/16)*log(1/16))=4\n",
    "        每个事件概率相同时，熵最大，这件事越不稳定。"
   ],
   "id": "4a3d45bb216af1b1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "    1.2.案例\n",
    "    篮球比赛里，有4个球队（A，B，C，D），获胜概率分别为(1/2,1/4,1/8,1/8)，求Ent(D)\n",
    "![jupyter](../Sources/Pictures/Decision_Tree_Algorithm/篮球比赛信息熵.png)"
   ],
   "id": "4f88c3e225103145"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "2.决策树划分依据一 ： 信息增益",
   "id": "e281477addf398ed"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "    2.1.概念\n",
    "    （1）信息增益：以某特征划分数据集前后的熵差值。熵可以表示样本集合的不确定性，熵越\n",
    "        大，样本呢的不确定性越大。因此可以使用划分前后集合熵的差值来衡量使用当前特征\n",
    "        对于样本集合D划分效果的好坏。\n",
    "    （2）信息增益=Entroy(前)-Entroy(后)\n",
    "    注意：信息增益表示得知特征X的信息而使得类Y的信息熵减小的程度\n",
    "    （3）定义与公式：\n",
    "        假定：离散属性a有V个可能的取值：a^1, a^2, ……，a^V\n",
    "        假定：离散属性性别有2个可能的取值（男，女）\n",
    "        若使用a来对样本集D进行划分，则会产生V个分支结点\n",
    "        其中第v个分支结点包含了D中所有在属性a上取值为a^v的样本，记为D^v.\n",
    "        我们可以根据前面给出的信息熵公式计算出D^v的信息熵，再考虑到不同的分支结点所\n",
    "        包含的样本数不同，给分支节点赋予权重|D^v| / |D|\n",
    "        即样本数越多的分支节点的影响越大，于是可计算出用属性a对样本集D进行划分所获得\n",
    "        的“信息增益”（information gain）\n",
    "        其中：\n",
    "            特征a对训练数据集D的信息增益Gain(D,a),定义为集合D的信息熵Ent(D)与给定特征a条件下D的信息条件熵Ent(D∣a)之差，即公式为：\n",
    "        公式详解：\n",
    "![jupyter](../Sources/Pictures/Decision_Tree_Algorithm/信息增益公式.png)"
   ],
   "id": "42efab73e120fdda"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "    （a）信息熵的计算：\n",
    "![jupyter](../Sources/Pictures/Decision_Tree_Algorithm/信息增益公式详解-1.png)"
   ],
   "id": "7af741ba0f983a90"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "    （b）条件熵的计算：\n",
    "    D^v:表示a属性中第v个分支节点包含的样本数\n",
    "    C^(kv):表示a属性中第v个分支节点包含的样本数中，第k个类别下包含的样本数\n",
    "![jupyter](../Sources/Pictures/Decision_Tree_Algorithm/信息增益公式详解-2.png)"
   ],
   "id": "d1a24b8d857cd8cf"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "    一般而言，信息增益越大，则意味着使用属性 a 来进行划分所获得的\"纯度提升\"越大。因此\n",
    "    ，我们可用信息增益来进行决策树的划分属性选择，著名的 ID3 决策树学习算法 \n",
    "    [Quinlan， 1986] 就是以信息增益为准则来选择划分属性。\n",
    "    其中，ID3 名字中的 ID 是 Iterative Dichotomiser (迭代二分器)的简称"
   ],
   "id": "abea92209425486b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "    2.2.案例\n",
    "    如下图，第一列为论团号码，第二列为性别，第三列为活跃度，最后一列为用户是否流失\n",
    "    我们要解决第一个问题：性别和活跃度两个特征，哪个对用户流失影响更大？\n",
    "![jupyter](../Sources/Pictures/Decision_Tree_Algorithm/信息增益案例1.png)"
   ],
   "id": "8def0c2dd4d7ed81"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "    通过计算信息增益可以解决这问题，统计右表信息。\n",
    "    其中Positive为正样本（已流失），Negative为负样本（未流失），下面的数值为不同划\n",
    "    分下对应的人数。\n",
    "    可以得到三个熵："
   ],
   "id": "761d7d2ad13243d9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "    a、计算类别信息熵\n",
    "    整体熵：\n",
    "![jupyter](../Sources/Pictures/Decision_Tree_Algorithm/信息增益案例1计算-1.png)"
   ],
   "id": "3ae5d985a263dd4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "    b、计算性别属性的信息熵（a=“性别”）\n",
    "![jupyter](../Sources/Pictures/Decision_Tree_Algorithm/信息增益案例1计算-2.png)"
   ],
   "id": "2138323abd7fda35"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "    b、计算性别的信息增益（a=“性别”）\n",
    "![jupyter](../Sources/Pictures/Decision_Tree_Algorithm/信息增益案例1计算-3.png)"
   ],
   "id": "96c94e9711a3729b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "    c、计算活跃度属性的信息熵（a=“活跃度”）\n",
    "![jupyter](../Sources/Pictures/Decision_Tree_Algorithm/信息增益案例1计算-4.png)"
   ],
   "id": "8a0b362b21bf9b0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "    c、计算活跃的信息增益（a=“活跃度”）\n",
    "![jupyter](../Sources/Pictures/Decision_Tree_Algorithm/信息增益案例1计算-5.png)"
   ],
   "id": "c0d1dc4d83d8bc97"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "    活跃度的信息增益比性别的信息增益大，也就是说，活跃度对用户流失的影响比性别大。在做\n",
    "    特征选择或者数据分析的时候，我们应该重点考察活跃度这个指标。"
   ],
   "id": "3e320615030d7925"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
