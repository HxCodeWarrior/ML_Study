{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "模型评估",
   "id": "b612401bc8b82048"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "1.误差平方和(SSE\\The sum of squares due to error)：",
   "id": "2787d1a447bc890e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "    举例（下图中数据-0.2，+0.4，-0.8，+1.3，-0.7，均为真实值和预测值的差）\n",
    "![jupyter](../Sources/Pictures/Clustering_Algorithms/模型评估SSE举例.png) "
   ],
   "id": "c784e4938693e2ed"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "    在k-means中的应用：\n",
    "![jupyter](../Sources/Pictures/Clustering_Algorithms/SSE.png)"
   ],
   "id": "208c99938f0bc9d9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "![jupyter](../Sources/Pictures/Clustering_Algorithms/SSE在k-means中的应用.png)",
   "id": "33d15ff87e72dadc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "    公式各部分内容\n",
    "![jupyter](../Sources/Pictures/Clustering_Algorithms/SSE公式各部分内容图解.png)"
   ],
   "id": "b6bd9b3e155a6171"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "    上图中；k=2\n",
    "    SSE图最终的结果，对图松散程度的衡量(eg:SSE（左图）< SSE（右图）)\n",
    "    SSE随着聚类迭代，其值会越来越小，直到最后趋于稳定："
   ],
   "id": "f16938884d0ed44e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "    如果质心的初始值选择不好，SSE只会达到一个不怎么好的局部最优解",
   "id": "26fe71b6ac2fdbc7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "2.“肘”方法（Elbow method）——K值确定",
   "id": "99d6cda1e7bb574a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "![jupyter](../Sources/Pictures/Clustering_Algorithms/“肘”方法（Elbow%20method）.png)",
   "id": "28145a4f44cca89b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "    （1）对于n个点的数据集，迭代计算k from 1 to n，每次聚类完成后计算每个点到其所\n",
    "        属的簇中心的距离的平方和；\n",
    "    （2）平方和是会逐渐变小的，直到k==n时平方和为0，因为每个点都是它所在的簇中心本身。\n",
    "    （3）在这个平方和变化过程中，会出现一个拐点也即“肘”点，下降率突然变缓时即认为是最佳的k值。\n",
    "    在决定什么时候停止训练时，肘形判据同样有效，数据通常有更多的噪音，在增加分类无法带\n",
    "    来更多回报时，我们停止增加类别。"
   ],
   "id": "f7e65b47c19a16f8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "3.轮廓系数法（Silhouette Coefficient）",
   "id": "f07a3014d818a06e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "    结合了聚类的凝聚度（Cohesion）和分离度（Separation），用于评估聚类的效果\n",
    "![jupyter](../Sources/Pictures/Clustering_Algorithms/轮廓系数法（Silhouette%20Coefficient）.png)"
   ],
   "id": "bb7de5a605c7c44c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "    目的：内部距离最小化，外部距离最大化\n",
    "![jupyter](../Sources/Pictures/Clustering_Algorithms/轮廓系数法目的.png)"
   ],
   "id": "be8ce83baadb811"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "    计算样本i到同簇其他样本的平均距离ai，ai 越小样本i的簇内不相似度越小，说明样本i越\n",
    "    应该被聚类到该簇。\n",
    "    计算样本i到最近簇Cj 的所有样本的平均距离bij，称样本i与最近簇Cj 的不相似度，定义\n",
    "    为样本i的簇间不相似度：bi =min{bi1, bi2, ..., bik}，bi越大，说明样本i越不\n",
    "    属于其他簇。\n",
    "    求出所有样本的轮廓系数后再求平均值就得到了平均轮廓系数。\n",
    "    平均轮廓系数的取值范围为[-1,1]，系数越大，聚类效果越好。\n",
    "    簇内样本的距离越近，簇间样本距离越远"
   ],
   "id": "ca97822c185c9b3c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "    案例：\n",
    "    下图是500个样本含有2个feature的数据分布情况，我们对它进行SC系数效果衡量：\n",
    "![jupyter](../Sources/Pictures/Clustering_Algorithms/SC系数案例数据.png)"
   ],
   "id": "ddd5a5a98d993a6f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "    n_clusters = 2 The average silhouette_score is : 0.7049787496083262\n",
    "    n_clusters = 3 The average silhouette_score is : 0.5882004012129721\n",
    "    n_clusters = 4 The average silhouette_score is : 0.6505186632729437\n",
    "    n_clusters = 5 The average silhouette_score is : 0.56376469026194\n",
    "    n_clusters = 6 The average silhouette_score is : 0.4504666294372765\n",
    "    n_clusters 分别为 2，3，4，5，6时，SC系数如下，是介于[-1,1]之间的度量指标：\n",
    "    每次聚类后，每个样本都会得到一个轮廓系数，当它为1时，说明这个点与周围簇距离较远，\n",
    "    结果非常好，当它为0，说明这个点可能处在两个簇的边界上，当值为负时，暗含该点可能被误分了。\n",
    "    从平均SC系数结果来看，K取3，5，6是不好的，那么2和4呢？"
   ],
   "id": "cd30330faf329d9b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "    k=2的情况：\n",
    "![jupyter](../Sources/Pictures/Clustering_Algorithms/SC系数案例-1.png)"
   ],
   "id": "328363a516b9befc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "    k=4的情况：\n",
    "![jupyter](../Sources/Pictures/Clustering_Algorithms/SC系数案例-2.png)"
   ],
   "id": "755967845550123d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "    n_clusters = 2时，第0簇的宽度远宽于第1簇；\n",
    "    n_clusters = 4时，所聚的簇宽度相差不大，因此选择K=4，作为最终聚类个数。"
   ],
   "id": "fc816fdafc6d9d27"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "4.CH系数（Calinski-Harabasz Index）",
   "id": "207c730690c375de"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "    Calinski-Harabasz：\n",
    "    类别内部数据的协方差越小越好，类别之间的协方差越大越好（换句话说：类别内部数据的距\n",
    "    离平方和越小越好，类别之间的距离平方和越大越好），\n",
    "    这样的Calinski-Harabasz分数s会高，分数s高则聚类效果越好。\n",
    "![jupyter](../Sources/Pictures/Clustering_Algorithms/CH系数公式.png)"
   ],
   "id": "fe0cbc38e0970b8b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "    tr为矩阵的迹, Bk为类别之间的协方差矩阵，Wk为类别内部数据的协方差矩阵;\n",
    "    m为训练集样本数，k为类别数。\n",
    "![jupyter](../Sources/Pictures/Clustering_Algorithms/CH系数矩阵的迹.png)"
   ],
   "id": "997a331b7d83d0aa"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "    使用矩阵的迹进行求解的理解：\n",
    "    矩阵的对角线可以表示一个物体的相似性\n",
    "    在机器学习里，主要为了获取数据的特征值，那么就是说，在任何一个矩阵计算出来之后，都\n",
    "    可以简单化，只要获取矩阵的迹，就可以表示这一块数据的最重要的特征了，这样就可以把很\n",
    "    多无关紧要的数据删除掉，达到简化数据，提高处理速度。"
   ],
   "id": "3816f58df836a6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "    CH需要达到的目的：\n",
    "    用尽量少的类别聚类尽量多的样本，同时获得较好的聚类效果。"
   ],
   "id": "ae57abff222db5bc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "5 小结",
   "id": "88028566fabb147c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "    sse【知道】\n",
    "        误差平方和的值越小越好\n",
    "    肘部法【知道】\n",
    "        下降率突然变缓时即认为是最佳的k值\n",
    "    SC系数【知道】\n",
    "        取值为[-1, 1]，其值越大越好\n",
    "    CH系数【知道】\n",
    "        分数s高则聚类效果越好\n",
    "        CH需要达到的目的：用尽量少的类别聚类尽量多的样本，同时获得较好的聚类效果。"
   ],
   "id": "9af937d799c4d5d1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
