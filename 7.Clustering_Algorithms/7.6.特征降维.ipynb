{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 特征降维",
   "id": "67faf9f3878134"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "    学习目标\n",
    "        了解降维的定义\n",
    "        知道通过低方差过滤实现降维过程\n",
    "        知道相关系数实现降维的过程\n",
    "        知道主成分分析法实现过程"
   ],
   "id": "3f4d2e2625e72988"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 1.降维",
   "id": "a5d32b9a48e7520e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "    1.1 定义\n",
    "    降维是指在某些限定条件下，降低随机变量(特征)个数，得到一组“不相关”主变量的过程"
   ],
   "id": "96ac6fcca436c57e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "    降低随机变量的个数\n",
    "![jupyter](../Sources/Pictures/Clustering_Algorithms/降维-1.png)"
   ],
   "id": "a08d7a8de2c0fd77"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "    相关特征(correlated feature)\n",
    "        相对湿度与降雨量之间的相关\n",
    "        等等\n",
    "    正是因为在进行训练的时候，我们都是使用特征进行学习。如果特征本身存在问题或者特征之\n",
    "    间相关性较强，对于算法学习预测会影响较大"
   ],
   "id": "fff0d72c4df5c914"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "    1.2 降维的两种方式\n",
    "        （1）特征选择\n",
    "        （2）主成分分析（可以理解一种特征提取的方式）"
   ],
   "id": "ad1a33805245821"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 2.特征选择",
   "id": "a541318fb23ce4d2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "    2.1 定义\n",
    "    数据中包含冗余或无关变量（或称特征、属性、指标等），旨在从原有特征中找出主要特征。\n",
    "![jupyter](../Sources/Pictures/Clustering_Algorithms/鸟类特征选择.png)"
   ],
   "id": "97df090fdf0f9ad5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "    2.2 方法\n",
    "    Filter(过滤式)：主要探究特征本身特点、特征与特征和目标值之间关联\n",
    "        方差选择法：低方差特征过滤\n",
    "        相关系数\n",
    "    Embedded (嵌入式)：算法自动选择特征（特征与目标值之间的关联）\n",
    "        决策树:信息熵、信息增益\n",
    "        正则化：L1、L2\n",
    "        深度学习：卷积等"
   ],
   "id": "90fb79f18bf961b1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "    2.3 低方差特征过滤\n",
    "    删除低方差的一些特征，前面讲过方差的意义。再结合方差的大小来考虑这个方式的角度。\n",
    "        特征方差小：某个特征大多样本的值比较相近\n",
    "        特征方差大：某个特征很多样本的值都有差别\n",
    "    \n",
    "    2.3.1 API\n",
    "    sklearn.feature_selection.VarianceThreshold(threshold = 0.0)\n",
    "        （1）作用：删除所有低方差特征\n",
    "        （2）方法：Variance.fit_transform(X)\n",
    "            参数：X:numpy array格式的数据[n_samples,n_features]\n",
    "            返回值：训练集差异低于threshold的特征将被删除。默认值是保留所有非零方\n",
    "                   差特征，即删除所有样本中具有相同值的特征。"
   ],
   "id": "94721aff5d32c744"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "    举例：\n",
    "    我们对某些股票的指标特征之间进行一个筛选，除去'index,'date','return'列不考虑\n",
    "    （这些类型不匹配，也不是所需要指标）"
   ],
   "id": "174db08853660f2a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "    pe_ratio,pb_ratio,market_cap,return_on_asset_net_profit,\n",
    "    du_return_on_equity,ev,earnings_per_share,revenue,total_expense"
   ],
   "id": "6b0ccf892ae2a57f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "    分析：\n",
    "        （1）初始化VarianceThreshold，指定阈值方差\n",
    "        （2）调用fit_transform"
   ],
   "id": "8c22cf750b7ca20d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_selection import VarianceThreshold \n",
    "\n",
    "def variance_demo():\n",
    "    \"\"\"\n",
    "    :function:降低方差特征——特征选择\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    data = pd.read_csv()\n",
    "    print(data)\n",
    "    # 1.实例化一个转换器类\n",
    "    transfer = VarianceThreshold(threshold=1)\n",
    "    # 2.调用fit_transform\n",
    "    data = transfer.fit_transform(data.iloc[:, 1:10])\n",
    "    print(\"删除低方差特征的结果：\\n\",data)\n",
    "    print(\"形状：\\n\", data.shape)"
   ],
   "id": "334c323f04e94b42"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 2.4.相关系数",
   "id": "766b1d1b325ec26a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "    主要实现方式：\n",
    "        皮尔逊相关系数\n",
    "        斯皮尔曼相关系数"
   ],
   "id": "50a5a596183e3642"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "    2.4.1 皮尔逊相关系数(Pearson Correlation Coefficient)\n",
    "        1.作用：反映变量之间相关关系密切程度的统计指标\n",
    "        2.公式计算案例(了解，不用记忆)\n",
    "        公式\n",
    "![jupyter](../Sources/Pictures/Clustering_Algorithms/pearson_fromula.png)"
   ],
   "id": "298634b9dcd7df1e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "        举例：比如说我们计算年广告费投入与月均销售额度\n",
    "![jupyter](../Sources/Pictures/Clustering_Algorithms/pearson_fromula案例数据.png)"
   ],
   "id": "35b2f90dba310f2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "    那么之间的相关系数怎么计算\n",
    "![jupyter](../Sources/Pictures/Clustering_Algorithms/pearson_fromula案例计算.png)"
   ],
   "id": "5c0f955897ba614f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "    最终计算：\n",
    "![jupyter](../Sources/Pictures/Clustering_Algorithms/pearson_fromula最终计算.png)"
   ],
   "id": "e1ec21939d9ea58f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "    所以我们最终得出结论是广告投入费与月平均销售额之间有高度的正相关关系。",
   "id": "f8982c8eeb3e6d86"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "            3.特点\n",
    "                相关系数的值介于–1与+1之间，即–1≤ r ≤+1。其性质如下：\n",
    "                （1）当r>0时，表示两变量正相关，r<0时，两变量为负相关\n",
    "                （2）当|r|=1时，表示两变量为完全相关，当r=0时，表示两变量间无相关关系\n",
    "                （3）当0<|r|<1时，表示两变量存在一定程度的相关。且|r|越接近1，两\n",
    "                变量间线性关系越密切；|r|越接近于0，表示两变量的线性相关越弱\n",
    "                （4）一般可按三级划分：|r|<0.4为低度相关；0.4≤|r|<0.7为显著性\n",
    "                相关；0.7≤|r|<1为高度线性相关\n",
    "            4.API\n",
    "            from scipy.stats import pearsonr\n",
    "                x : (N,) array_like\n",
    "                y : (N,) array_like \n",
    "                Returns: (Pearson’s correlation coefficient, p-value)"
   ],
   "id": "5b366515a93ab5d1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "    2.4.2 斯皮尔曼相关系数(Rank IC)\n",
    "        1.作用：反映变量之间相关关系密切程度的统计指标\n",
    "        2.公式计算案例(了解，不用记忆)\n",
    "    公式:\n",
    "        n为等级个数，d为二列成对变量的等级差数\n",
    "![jupyter](../Sources/Pictures/Clustering_Algorithms/Rank%20IC公式.png)"
   ],
   "id": "7527679ffbe19c51"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "        Rank_IC举例：\n",
    "![jupyter](../Sources/Pictures/Clustering_Algorithms/Rank_IC举例数据.png)"
   ],
   "id": "c056f6b3cbf1fb52"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "        3.特点：\n",
    "            （1）斯皮尔曼相关系数表明 X (自变量) 和 Y (因变量)的相关方向。 如果当\n",
    "            X增加时， Y 趋向于增加, 斯皮尔曼相关系数则为正.\n",
    "            （2）与之前的皮尔逊相关系数大小性质一样，取值 [-1, 1]之间"
   ],
   "id": "22acb7a70118ad40"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "        4.API\n",
    "        from scipy.stats import spearmanr"
   ],
   "id": "17d5a6e3368426bb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T06:05:57.974634Z",
     "start_time": "2024-07-19T06:05:56.989570Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 5.案例\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "x1 = [12.5, 15.3, 23.2, 26.4, 33.5, 34.4, 39.4, 45.2, 55.4, 60.9]\n",
    "x2 = [21.2, 23.9, 32.9, 34.1, 42.5, 43.2, 49.0, 52.8, 59.4, 63.5]\n",
    "\n",
    "spearmanr(x1, x2)"
   ],
   "id": "46c3f5bad1eaa6a4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SignificanceResult(statistic=np.float64(0.9999999999999999), pvalue=np.float64(6.646897422032013e-64))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3.主成分分析",
   "id": "d9c23dc4dd17f765"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "    3.1.什么是主成分分析（PCA）\n",
    "        （1）定义：高维数据转换为低维数据的过程，在此过程中，可能会舍弃原有数据、创造新的变量\n",
    "        （2）作用：是数据维数压缩，尽可能降低原数据的维数（复杂度），损失少量信息\n",
    "        （3）应用：回归分析或者聚类分析当中\n",
    "        对于信息一词，在决策树中回进行介绍"
   ],
   "id": "3479414039425e8d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "    那么更好的理解这个过程？我们来看这样一张图\n",
    "![jupyter](../Sources/Pictures/Clustering_Algorithms/PCA解释图.png)"
   ],
   "id": "1c7cd6d718af1068"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "    3.2 API\n",
    "    sklearn.decomposition.PCA(n_components=None)\n",
    "        （1）作用：将数据分解为较低维数空间\n",
    "        （2）参数：\n",
    "                n_components:\n",
    "                    小数：表示保留百分之多少的信息\n",
    "                    整数：减少到多少特征\n",
    "        （3）方法：PCA.fit_transform(X) X:numpy array格式的数据[n_samples,n_features]\n",
    "        （4）返回值：转换后指定维度的array"
   ],
   "id": "c2aeca451810c3b9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 4.小结",
   "id": "f9f0742f000840cc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "    降维的定义【了解】\n",
    "        （1）就是改变特征值，选择哪列保留，哪列删除\n",
    "        （2）目标是得到一组”不相关“的主变量\n",
    "    降维的两种方式【了解】\n",
    "        （1）特征选择\n",
    "        （2）主成分分析（可以理解一种特征提取的方式）\n",
    "    特征选择【知道】\n",
    "        （1）定义：提出数据中的冗余变量\n",
    "        （2）方法：\n",
    "            Filter(过滤式)：主要探究特征本身特点、特征与特征和目标值之间关联\n",
    "                方差选择法：低方差特征过滤\n",
    "                相关系数\n",
    "            Embedded (嵌入式)：算法自动选择特征（特征与目标值之间的关联）\n",
    "                决策树:信息熵、信息增益\n",
    "                正则化：L1、L2\n",
    "    低方差特征过滤【知道】\n",
    "        把方差比较小的某一列进行剔除\n",
    "        api:sklearn.feature_selection.VarianceThreshold(threshold = 0.0)\n",
    "            删除所有低方差特征\n",
    "            注意，参数threshold一定要进行值的指定\n",
    "    相关系数【掌握】\n",
    "        主要实现方式：\n",
    "            皮尔逊相关系数\n",
    "            斯皮尔曼相关系数\n",
    "    皮尔逊相关系数\n",
    "        通过具体值的大小进行计算\n",
    "        相对复杂\n",
    "        api:from scipy.stats import pearsonr\n",
    "            返回值，越接近|1|，相关性越强；越接近0，相关性越弱\n",
    "    斯皮尔曼相关系数\n",
    "        通过等级差进行计算\n",
    "        比上一个简单\n",
    "        api:from scipy.stats import spearmanr\n",
    "            返回值，越接近|1|，相关性越强；越接近0，相关性越弱\n",
    "    pca【知道】\n",
    "        定义：高维数据转换为低维数据，然后产生了新的变量\n",
    "        api:sklearn.decomposition.PCA(n_components=None)\n",
    "            n_components\n",
    "                整数 -- 表示降低到几维\n",
    "                小数 -- 保留百之多少的信息"
   ],
   "id": "94e6f52d6a059c42"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
