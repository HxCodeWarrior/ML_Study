{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "KNN算法总结",
   "id": "6c3fc47e72bc4d53"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "    1.优点",
   "id": "bbbfe3dd78ba36ad"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "        （1）简单有效\n",
    "        （2）重新训练的代价低\n",
    "        （3）适合类域交叉样本\n",
    "            * 类域交叉样本：存在样本属性较差较多\n",
    "            * KNN方法主要靠周围有限的邻近的样本，而不是靠判断类域的方法来确定所属类别\n",
    "              的，因此对于类域较差或者重叠较多的待分样本集来说，KNN方法较其他方法更加\n",
    "              合适。\n",
    "        （3）适合大样本呢自动分类\n",
    "            * KNN算法比较适用于样本容量比较大的类域的自动分类，而那些样本容量较小的类\n",
    "              域采用这种算法比较容易发生误分"
   ],
   "id": "d3623e919d560a99"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "    2.缺点",
   "id": "86b7294de1b52017"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "        （1）惰性学习\n",
    "            KNN算法时懒散学习方法（lazy learning，基本上不学习），一些积极学习的算法要快很多\n",
    "        （2）类别评分不是规格化\n",
    "            不像一些通过概率评分的分类\n",
    "        （3）输出可解释性不强\n",
    "            例如：决策树的输出可解释性就较强\n",
    "        （4）对不均衡的样本不擅长\n",
    "            当样本不均衡时，如一个类的样本容量很大，而其他样本呢容量很小时，有可能导致\n",
    "            当输入一个新样本时，该样本的k个邻域中大容量类的样本占比较大。该算法只计算”\n",
    "            最近“的邻居样本，某一类的样本数量很大，那么或者这类样本很靠近目标样本。无\n",
    "            论怎么样，数量并不影响运行结果，可以采用权值的方法（和该样本距离小的邻居权\n",
    "            值大）来改造。\n",
    "        （4）计算量大\n",
    "            目前常用的解决方法：事先对已知样本点进行剪辑，事先去处对分类作用不大的样本。"
   ],
   "id": "262927b0453ff481"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
