{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "kd树",
   "id": "2417309d9ff60515"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "    问题导入：\n",
    "        实现k近邻算法时，主要考虑的问题是如何对训练数据继续宁快速k近邻搜索。\n",
    "        这个特征空间的维数大以及训练数据容量大时尤其必要。\n",
    "        k近邻算法最简单拿的实现是线性扫描（穷举搜索），即要计算输入实例与每一个训练实例\n",
    "        的距离，计算并存储好以后，再查找k近邻。当训练集相当大时，计算非常耗时。\n",
    "        为了提高kNN搜索的效率，可以考虑使用特殊的结构存储训练数据，以减小计算距离的次数"
   ],
   "id": "d18c7c381378721a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "    1.kd树简介\n",
    "        1.1 什么是kd树\n",
    "            （1）引入：根据kNN每次需要预测一个点时，我们都需要计算训练数据集里每个点\n",
    "            到这个点的距离，然后选出距离最近的k个点进行投票，当数据集很大时，这个计算\n",
    "            成本非常高。\n",
    "            （2）kd树\n",
    "                为了避免每次都重新计算一遍距离，算法会把距离信息保存在一棵树中，这样在计算之前哦操你个梳理查询距离信息，尽量避免重新计算\n",
    "                其基本原理：如果A和B距离很远，B和C距离很近，那么A和C的距离也很远\n",
    "                          有了这个信息，就可以再合适的时候跳过距离远的点\n",
    "                这样优化后的算法复杂度可以降到O（DNiog（N）），\n",
    "                可以参考文献Bentiey，J.L，Communications of the ACM（1975）\n",
    "            （3）Ball Tree算法，在kd Tree的基础上对性能能、进一步进行了优化。\n",
    "        1.2 原理\n",
    "            "
   ],
   "id": "1a887a1431f708b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "    2.kd树的构建\n",
    "        （1）构造根节点。使根节点对应于k维空间中包含所有实例点的超矩形区域\n",
    "        （2）通过递归的方法，不断地对k维孔吉纳进行切分，生成子节点。\n",
    "            在超矩形区域上选择一个坐标轴和在此坐标轴上的一个切分点，确定一个超平面，这\n",
    "            个超平面通过选定的切分点并垂直选定的坐标轴，将当前超矩形区域切分为左右两个\n",
    "            子区域（子节点）；这时，实例被分割到两个子区域。\n",
    "        （3）上述过程直到子区域内没有实例终止（终止时的节点为叶节点）\n",
    "            在此过程中，将实例保存在相应的节点上。\n",
    "        （4）通常，循环的选择坐标轴对空间切分，选择训练实例点在坐标轴上的中位数为切分点\n",
    "            ，这样得到的kd树是平衡的（平衡二叉树：它是一棵空树，或其左子树和右子树的深\n",
    "            度只差绝对值不超过1，且它的左子树和右子树都是平衡二叉树）\n",
    "            \n",
    "        KD树中每个节点是一个向量，和二叉树按照数的大小换分为不同的量，KD树每层需要选定\n",
    "        向量中的某一维，然后根据这一维按照左小右大的方式划分数据。在构造KD树时，关键需\n",
    "        要解决两个问题：\n",
    "            （1）选择向量的哪一维进行划分\n",
    "                解决：可以随计算则某一维或者按顺序选择，但是更好的方法应该是在数据比\n",
    "                较分数的那一维进行划分（分散的程度可以根据方差来衡量）\n",
    "            （2）如何划分数据\n",
    "                解决：好的划分方法可以使构造的树比较平衡，可以每次选择中位数来进行划分。"
   ],
   "id": "88c335c666a2c348"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "    3.如何在kd树中搜索\n",
    "        3.1 最近邻域搜索（Nearest-Neighbor Lookup0）\n",
    "            （1）kd树是一种对k为空间中的实例点及性能存储一边对其进行快速搜索的树形数\n",
    "                据结构。\n",
    "            （2）kd树是一种二叉树，表示对k维空间的一个划分。\n",
    "            （3）构造kd树相当于不断地用垂直于坐标值的超平面将k维空间切分，构成一系列\n",
    "                的k维超矩形区域。kd树的每个结点对应于一个k维超矩形区域，利用kd树可以\n",
    "                省去对大部分数据点的搜索，从而减少搜索的计算量。\n",
    "            （4）类比“二分查找”，给出一组数据{9，1，4，7，2，5，0，6，3，8}，要查找8.\n",
    "                如果挨个查找（线性扫描），那么将会把数据集都遍历一遍。\n",
    "                如果把原有数据集进行排序{0，1，2，3，4，5，6，7，8，9}，按照长一种\n",
    "                方式我们进行了很多没必要的查找，现在如果我们以5为分界点，那么数据集就\n",
    "                被划分为了左右两个“簇”[0,1,2,3,4]和[6,7,8,9]\n",
    "                因此，根本就没必要进入第一个簇，可以直接进入第二个簇进行查找。把二分\n",
    "                查找中的数据点换成k维数据点，这样的划分就变成了用超平面对k维空间的划\n",
    "                分，空间划分就是对数据点进行分类，靠的近的数据点就在一个空间中。\n",
    "            "
   ],
   "id": "2d8f974e911277d2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "21d20b6d43d0c8b5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
