{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "过拟合和欠拟合介绍",
   "id": "33cd636111d57de4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "1.定义",
   "id": "43ca163205181ec5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "    （1）过拟合：一个假设在训练数据上能够获得比其他假设更好的拟合，但是在测试数据集上却\n",
    "              不能很好地拟合数据，此时认为这个假设出现了过拟合地现象。（模型过于复杂）\n",
    "    （2）过拟合：一个假设在训练数据上不能获得更好的拟合，并且在测试数据上也不能很好地拟 \n",
    "              合数据，此时认为这个假设出现了欠拟合现象。（模型过于简单）"
   ],
   "id": "d0d1119c797e4b16"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "![jupyter](../Sources/Pictures/Linear_Regression/过拟合与欠拟合图解.png)",
   "id": "f361ab767ead03ef"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "    那么是什么原因导致模型复杂？线性回归进行训练学习的时候变成模型会变得复杂，这里就对\n",
    "    应前面再说的线性回归地两种关系，非线性数据，也就是存在很多无用的特征或者现实中地事\n",
    "    物特征跟目标值地关系并不是简单地线性关系。"
   ],
   "id": "68e815e9dbcf58f1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "2.原因以及解决办法",
   "id": "9c9e6404861e5c65"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "    （1）欠拟合原因以及解决办法\n",
    "        （1.1）原因：学习到的数据特征过少\n",
    "        （1.2）解决办法：\n",
    "            （a）添加其他特征项，有时候我们模型会出现欠拟合的时候是因为特征选项不够\n",
    "            导致的，可以添加其他特征项来很好地解决，例如，“组合”、“泛化”、“相关性”\n",
    "            三类特征是特征添加的重要手段，无论在什么场景，都可以照葫芦画瓢，总会得到\n",
    "            意想不到的效果。跟踪上面的特征除外，“上下文特征”、“平台特征”等等，都可\n",
    "            以作为特征添加的首选项。\n",
    "            （b）添加多项式特征。这个在机器学习算法里用的很普遍，\n",
    "            例如：将线性模型通过添加二次项或者三次项使模型泛化能力更强。\n",
    "    （2）过拟合原因以及解决办法\n",
    "        （2.1）原因：原始特征过多，存在一些嘈杂特征，模型过于复杂是因为模型尝试去兼顾各个测试数据点。\n",
    "        （2.2）解决办法：\n",
    "            （a）重新清洗数据，导致过拟合的一个原因也可能是数据不纯导致的，如果数据出现了过拟合就需要我们重新清洗数据。\n",
    "            （b）增大数据的训练量。还有一个原因就是我们用于训练的数据量太小导致的，训练数据占总数据的比例过小。\n",
    "            （c）正则化\n",
    "            （d）减少特征维度，防止维灾难"
   ],
   "id": "8ef7986d16112812"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "3.正则化",
   "id": "b4e492ad323a7b9e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "    3.1.什么是正则化\n",
    "    在解决回归过拟合中，我们选择正则化，但是对于其他机器学习算法如分类算法来说也会出现\n",
    "    这样的问题，除了一些算法本身作用之外（决策树，神经网络等），我们更多的也是去自己做\n",
    "    特征选择，包括之前说的删除、合并一些特征。"
   ],
   "id": "a89976995ce215a1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "![jupyter](../Sources/Pictures/Linear_Regression/正则化解决拟合方案图解.png)",
   "id": "a639aa0f121b9c88"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "    如何解决？   \n",
    "    在学习的时候，数据提供的特征有些影响模型复杂度或者这个特征的数据点异常较多，所以算\n",
    "    法在学习的时候尽量减少这个特征的影响（伸着删除某个特征的影响），这就是正则化\n",
    "    \n",
    "    注意：调整的时候，算法并不知道某个特征影响，而是去调整参数得出优化结果\n",
    "![jupyter](../Sources/Pictures/Linear_Regression/正则化-如何解决.png)"
   ],
   "id": "6c1ec673ee060a80"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "    3.2.正则化类别\n",
    "        （1）L2正则化\n",
    "            （1.1）作用：可以使得其中一些W的都很小，都接近于0，削弱某个特征的影响。\n",
    "            （1.2）优点：越小的参数说明模型越简单，越简单的模型则越不容易产生过拟合现象\n",
    "            （3）Rdge回归（岭回归）\n",
    "        （2）L1正则化\n",
    "            （2.1）作用：可以使得其中一些W的值直接为0，删除这个特征的影响\n",
    "            （2.2）LASSO回归"
   ],
   "id": "e93f1b3b8a471770"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
