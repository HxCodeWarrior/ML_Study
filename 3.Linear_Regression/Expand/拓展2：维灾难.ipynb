{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "维灾难",
   "id": "c9ae06e7cf324347"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "1.什么是维灾难",
   "id": "bbc6ed09ee863e49"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "    随着维度的增加，分类器性能逐步上升，到达某个点之后，其性能便会逐渐下降\n",
    "![jupyter](../../Sources/Pictures/Linear_Regression/维灾难-1.png)"
   ],
   "id": "f33b1f791a6da55"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "    有一系列的图片，每张图片的内容可能是猫也可能是狗，我们需要构造一个分类器对猫、狗进\n",
    "    行自动的分类。首先，要寻找到一些能够描述猫和狗的特征，这样我们的分类算法就可以利用\n",
    "    这些特征去识别物体，猫和狗的皮毛颜色可能是一个很好的特征。考虑到红绿蓝构成图像的三\n",
    "    原色，因此用图片三原色各自的平均值称得上方便直观，这样有了一个简单的Fisher分类器："
   ],
   "id": "753a42852ebcb9d8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "![jupyter](../../Sources/Pictures/Linear_Regression/Fisher分类器.png)",
   "id": "1fd60b9c8967203b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "    使用颜色特征可能无法得到一个足够准确的分类器，如果是这样的话，\n",
    "    我们不妨假设诸如图片：\n",
    "        纹理（图像灰度值在其X、Y方向上的导数dx、dy），\n",
    "        就有5个特征（Red、Blue、Green、dx、dy）类设计我们的分类器\n",
    "    也许分类器准确率依然无法达到要求，加入更多特征，比如：颜色、纹理的统计信息等等，\n",
    "    如此下去，可能会得到上百个特征。那是不是我们的分类器性能会随着特侦数量的增加而逐步\n",
    "    提高呢？答案也许有些让人泪丧的，事实上，当特征数量达到一定规模后，分类器的性能是在\n",
    "    下降的。\n",
    "    也就是说：随着维度（特征数量）增加，分类器的性能下降。"
   ],
   "id": "bec1b8223dc91a2a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "2.维数灾难与过拟合  ",
   "id": "d4e2e9db09875e11"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "    我们假设猫和狗图片的数量是有限的（样本数量总是有限的），加黑色有10张图片，接下来我\n",
    "    们就用着10张图片来训练我们的分类器\n",
    "![jupyter](../../Sources/Pictures/Linear_Regression/分类器-0.png)"
   ],
   "id": "3c2dea40dcc24491"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "单一特征的分类器，在训练集上表现并不好",
   "id": "ed0f7b8528efacdc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "    增加以一个特征，比如绿色，这样特征维数就扩展到了2维\n",
    "    增加一个特征后，我们依然无法找到一条简单的直线将它们有效分类\n",
    "![jupyter](../../Sources/Pictures/Linear_Regression/分类器-1.png)"
   ],
   "id": "ef25f6a75ce7c2ed"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "    再增加一个特征，比如蓝色，扩展到三维特征空间：\n",
    "![jupyter](../../Sources/Pictures/Linear_Regression/分类器-2.png)"
   ],
   "id": "728f2af2ac3e6789"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "    在3维特征空间中，我们很容易找到一个分类平面，能够在训练集上有效地将猫和狗进行分类：\n",
    "    在高维空间中，我们似乎能得到更优地分类器性能。\n",
    "![jupyter](../../Sources/Pictures/Linear_Regression/分类器-3.png)"
   ],
   "id": "476ed302ad7885c8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "    从1维到3维，给我们地感受是：维数越高，分类性能越优越。然而，维数过高会导致一定的问题：\n",
    "    在一维特征空间下，我们假设一个维度的宽度为5个单位，这样样本呢密度维10/5=2.\n",
    "    在2维特征空间下，10个样本所分布地空间大小为25，这样样本呢密度为10/25=0.1.\n",
    "    在3维特征空间下，10个样本分布的空间大小为125，样本密度就为10/125=0.08\n",
    "    \n",
    "    过多的特征导致过拟合现象：训练集上训练的很好，大那是对于新数据就缺乏泛化能力。\n",
    "![jupyter](../../Sources/Pictures/Linear_Regression/分类器-4.png)"
   ],
   "id": "e89f1ae12bb3f06a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "    高维空间训练形成的线性分类器，相当于在低维空间地一个复杂的非线性分类器，这种分类器\n",
    "    过多地强调了训练集的准确率甚至对于一些低级错误/异常的数据也进行了学习。而正确的数\n",
    "    据却无法覆盖整个特征空间，为此，这样得到的分类器在对新数据进行预测时将会出现错误，\n",
    "    这种现象称之为过拟合，同时也是维灾难的直接体现。\n",
    "    \n",
    "    用2个特征代替3个特征进行分类器的学习：\n",
    "    尽管训练集上分类器准确率不如3维下的高，但是具备更好的泛化能力。\n",
    "![jupyter](../../Sources/Pictures/Linear_Regression/分类器-5.png)"
   ],
   "id": "ff56354bbe0d557b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "    简单的线性分类器在训练数据集上的表现不如非线性分类器，但是由于线性分类器的学习过程\n",
    "    对噪声没有对称线性分类器敏感，因此对新数据具备更优的泛化能力，换句话说，通过使用更\n",
    "    少的特征，避免了维数灾难的发生（也就是避免了高维情况下的过拟合）\n",
    "    \n",
    "    由于高维而带来的数据稀疏性问题：\n",
    "    假设有一个特征，它的数值范围在0到1之间均匀分布，并且对狗和猫来说，其值都是唯一的，\n",
    "    我们现在利用这个特征来设计分类器，如果我们的训练数据覆盖了取值范围的20%（e.g 0到\n",
    "    0.2），那么所使用的训练数据就占总样本量的20%.\n",
    "    到二维情况下，覆盖二维特征空间20%的面漆，则需要在每个维度上取得45%的取值范围\n",
    "    在三维情况下，要覆盖特征空间20%的体积，则需要在每个维度上取得58%的取值范围……\n",
    "    在维度接近一定程度时，要取得同样的训练样本呢数量，则几乎要在每个维度上取得接近样本\n",
    "    100%的取值范围，或者增加总样本数量，但是样本数量是有限的。\n",
    "    \n",
    "    如果一直增加特征数，由于样本分布越来越系数，如果要避免过拟合的而出现，就不得不持续增加样本数。"
   ],
   "id": "a84e330c0c3d5d8b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "![jupyter](../../Sources/Pictures/Linear_Regression/分类器-6.png)",
   "id": "d96b446e9874c48b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "    数据在高维空间的中心比在边缘区域具备更大的稀疏性，数据更倾向于分布在空间的边缘区域:\n",
    "    不属于单位圆的训练样本比在搜索空间的中心更接近搜索空间的角点。\n",
    "    这些样本很难分类，因为它们的特征值差别很大（例如，单位正方形的对焦样本）\n",
    "![jupyter](../../Sources/Pictures/Linear_Regression/分类器-7.png)"
   ],
   "id": "a6f9df37dca7d2b3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "    一个有趣的问题，当我们增加特征空间的维度时，圆（超球面）的体积如何相对于正方形（超立体）的体积发生变化，\n",
    "    尺寸d的单位超立方体的体积总是1^d=1，尺寸d和半径0.5的内切超球体的体积可以计算为：\n",
    "![jupyter](../../Sources/Pictures/Linear_Regression/内切超球体体积.png)"
   ],
   "id": "4cb574bed710a00a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "    在高维空间中，大多数训练数据驻留在定义特征空间的超立方体的角落中。如前所述，特征空\n",
    "    间角落中的实例比围绕超球体质心的实例难以分类\n",
    "![jupyter](../../Sources/Pictures/Linear_Regression/高维空间实例分类图解.png)"
   ],
   "id": "bb232cf39fc82a07"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "    在高维空间中，大多数训练数据驻留在定义特征空间的超立方体的角落中。如前所述，特征空间中的实例比围绕在超球体质心的实例难以分类：\n",
    "![jupyter](../../Sources/Pictures/Linear_Regression/高维空间实例分布图解.png)"
   ],
   "id": "51889e9eeb290332"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "    事实证明，许多事物在高维空间中表现得非常不同。例如：如果你选择一个单位平方（1x1平方）的随机点，他将只有大约0.4%的机会位于小于0.0001的边界（换句话说，随机点将沿着任何维度“极值”这是非常不可能的）。但是在一个10000维单位的超立方体（1x1x1立方体，有1万个1）中，这个概率大于99，99999999%，高维超立方体汇总的大部分待拿都非常接近边界，更难区分的是：如果你在一个单位正方形中随机抽取两个点，这两个点之间的距离平均约为0.52。如果在三维三位立方体中选取两个随机点，则平均距离将大约为0.66。但是在一个100万维的超立方体中随机抽取两个点，那么这个平均距离大约将为408.25（大约1,000,000/6）！",
   "id": "b3c5d7e99968db8a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
